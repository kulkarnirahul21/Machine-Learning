rm(list=ls(all=TRUE))
state.x77
head(state.x77)
str(state.x77)
st = as.data.frame(state.x77)
data = as.data.frame(state.x77)
summary(data)
str(data)
head(state.x77)
colnames(st)[4] = "LifeExp"                   # no spaces in variable names, please
> colnames(st)[6] = "HSGrad"
colnames(st)[6] = "HSGrad"
cor(data)                              # correlation matrix (not shown, yet)
round(cor(data), 3)
colnames(data)[4] = "LifeExp"                   # no spaces in variable names, please
colnames(data)[6] = "HSGrad"
rm(list=ls(all=TRUE))
# we will use a builtin dataset
str(state.x77) # this is not a dataframe
data = as.data.frame(state.x77)
summary(data)
str(data)
head(state.x77)
# Data cleaning
colnames(data)[4] = "LifeExp"                   # no spaces in variable names, please
colnames(data)[6] = "HSGrad"
sapply(data, )
colnames(data)
str(state.x77) # this is not a dataframe
data = as.data.frame(state.x77)
summary(data)
str(data)
colnames(data)
colnames(data)[4] = "LifeExp"                   # no spaces in variable names, please
colnames(data)[6] = "HSGrad"
head(data)
sapply(data, min(),2)
sapply(data, min())
sapply(data,2, min())
sapply(data, min())
apply(data,2,min)
apply(data,2,max)
apply(data,2,mean)
pairs(st)
pairs(data)
model1 = lm(Life.Exp ~ ., data=st)
model1 = lm(Life.Exp ~ ., data=data)
model1 = lm(LifeExp ~ ., data=data)
summary(model1)
model2 = update(model1, .~. -Area)
summary(model2)
anova(model2, model1)
model3 = update(model2, .~. -Illiteracy)
summary(model3)
model4 = update(model3, .~. -Income)
summary(model4)
model5 = update(model4, .~. -Density)
summary(model5)
anova(model5, model4)
anova(model5, model1)
anova(model5, model4)
model.int = update(model5, .~.^3)
summary(model.int)
model.int = update(model5, .~.^3) # interaction effect
summary(model.int)
step(model1, direction="backward")
predict(model5, list(Population=2000, Murder=10.5, HS.Grad=48, Frost=100))
predict(model5, list(Population=2000, Murder=10.5, HSGrad=48, Frost=100))
par(mfrow=c(2,2))                    # visualize all four graphs at once
plot(model5)
par(mfrow=c(1,1))
par(mfrow=c(2,2))                    # visualize all four graphs at once
plot(model5)
par(mfrow=c(1,1))
names(model5)
coef(model5)
model5$coefficients
model5$resid
confint(model5)
rm(list=ls(all=TRUE))
str(state.x77) # this is not a dataframe
data = as.data.frame(state.x77)
View(data)
summary(data)
str(data)
colnames(data)[4] = "LifeExp"                   # no spaces in variable names, please
colnames(data)[6] = "HSGrad"
head(data)
apply(data,2,min)
apply(data,2,max)
apply(data,2,mean)
View(data)
View(data)
cor(data)                              # correlation matrix (not shown, yet)
round(cor(data), 3)
pairs(data) # Plot correlation matrix.
View(data)
View(data)
model1 = lm(LifeExp ~ ., data=data)
colnames(data)
View(data)
View(data)
summary(model1)
model2 = update(model1, .~. -Area)
summary(model2)
anova(model2, model1)
model3 = update(model2, .~. -Illiteracy)
summary(model3)
model4 = update(model3, .~. -Income)
summary(model4)
model5 = update(model4, .~. -Density)
summary(model5)
anova(model5, model4)
anova(model5, model1)
model.int = update(model5, .~.^3) # interaction effect
summary(model.int)
predict(model5, list(Population=2000, Murder=10.5, HSGrad=48, Frost=100))
par(mfrow=c(2,2))                    # visualize all four graphs at once
plot(model5)
par(mfrow=c(1,1))
plot(model5)
par(mfrow=c(2,2))                    # visualize all four graphs at once
plot(model5)
par(mfrow=c(1,1))
summary(model5)
names(model5)
model5$coefficients
model5$coefficients
model5$resid
confint(model5)
step(model1, direction="backward")
predict(model1, list(Population=2000, Murder=10.5, HSGrad=48, Frost=100))
model1 = lm(LifeExp ~ ., data=data)
summary(model1)
predict(model1, list(Population=2000, Murder=10.5, HSGrad=48, Frost=100))
rm(list=ls(all=TRUE))
# we will use a builtin dataset
str(state.x77) # this is not a dataframe
data = as.data.frame(state.x77)
summary(data)
str(data)
colnames(data)
# Data cleaning
colnames(data)[4] = "LifeExp"                   # no spaces in variable names, please
colnames(data)[6] = "HSGrad"
head(data)
apply(data,2,min)
apply(data,2,max)
apply(data,2,mean)
#
cor(data)                              # correlation matrix (not shown, yet)
round(cor(data), 3)
model1 = lm(LifeExp ~ ., data=data)
summary(model)
summary(model1)
rm(list=ls(all=TRUE))
data = as.data.frame(state.x77)
summary(data)
str(data)
colnames(data)
# Data cleaning
colnames(data)[4] = "LifeExp"                   # no spaces in variable names, please
colnames(data)[6] = "HSGrad"
head(data)
apply(data,2,min)
apply(data,2,max)
apply(data,2,mean)
#
cor(data)                              # correlation matrix (not shown, yet)
round(cor(data), 3)
pairs(data) # Plot correlation matrix.
model1 = lm(LifeExp ~ ., data=data)
summary(model1)
setwd("C:/Users/kulka/Downloads/Machine-Learning/ML - Complete/R/")
library(caret)
train <- read.delim("flag.data")
View(train)
train <- read.ftable("flag.data")
train <- read.table("flag.data")
View(train)
train <- read.delim("flag.data")
View(train)
train <- read.delim("flag.data",sep = ",")
View(train)
train <- read.csv("flags.csv")
train <- train[,-1]
View(train)
index <- createDataPartition(train$landmass,p = 0.9,list = F)
train <- train[-index]
index <- createDataPartition(train$landmass,p = 0.9,list = T)
train <- train[-index]
index <- createDataPartition(train$landmass,p = 0.9)
index <- createDataPartition(train$landmass,p = 0.9,list = F)
train <- train[,-1]
train <- read.csv("flags.csv")
train <- train[,-1]
index <- createDataPartition(train$landmass,p = 0.9,list = F)
train <- train[-index]
train <- read.csv("flags.csv")
train <- train[,-1]
index <- createDataPartition(train$landmass,p = 0.9,list = T)
train <- train[-index]
test <- train[index]
train <- read.csv("flags.csv")
train <- train[,-1]
index <- createDataPartition(train$landmass,p = 0.9,list = T)
train <- train[index,]
test <- train[-index,]
train <- read.csv("flags.csv")
train <- train[,-1]
index <- createDataPartition(train$landmass,p = 0.9,list = F)
train <- train[index,]
test <- train[-index,]
data <- read.csv("flags.csv")
data <- data[,-1]
index <- createDataPartition(data$landmass,p = 0.9,list = F)
train <- data[index,]
test <- data[-index,]
names(train)
predictVar <- "religion"
predictors<-names(train)[!names(train) %in% predictVar]
predictors
model_rf<-train(train[,predictors],train[,outcomeName],method='rf')
model_rf<-train(train[,predictors],train[,predictVar],method='rf')
model_glm<-train(train[,predictors],train[,predictVar],method='svm')
model_rf<-train(train[,predictors],train[,predictVar],method='rpart')
model_rf
setwd("C:/Users/kulka/Downloads/Machine-Learning/ML - Complete/R/")
library(caret)
data <- read.csv("flags.csv")
data <- data[,-1]
index <- createDataPartition(data$landmass,p = 0.9,list = F)
trainSet <- data[index,]
testSet <- data[-index,]
predictVar <- "religion"
predictors<-names(trainSet)[!names(trainSet) %in% predictVar]
model_decision_trees<-train(trainSet[,predictors],trainSet[,predictVar],method='rpart')
model_decision_trees<-train(predictVar~.,method='rpart')
model_decision_trees<-train(predictVar~.,data = trainSet,method='rpart')
model_decision_trees<-train(predictVar~.,data = trainSet,method='rpart')
model_decision_trees<-train(trainSet[,predictors],trainSet[,predictVar],method='rpart')
set.seed(22)
model_decision_trees<-train(trainSet[,predictors],trainSet[,predictVar],method='rpart')
trainSet[,predictors]
model_decision_trees<-train(predictVar~.,data = trainSet,method='rpart',tuneGrid=expand.grid(mincriterion=0.95))
model_decision_trees<-train(predictVar ~ .,data = trainSet,method='rpart',tuneGrid=expand.grid(mincriterion=0.95))
model_decision_trees<-train("predictVar ~ .",data = trainSet,method='rpart',tuneGrid=expand.grid(mincriterion=0.95))
model_decision_trees<-train(predictVar ~ .,data = trainSet,method='rpart',tuneGrid=expand.grid(mincriterion=0.95))
model_decision_trees<-train(trainSet[,predictors],trainSet[,predictVar],method='rpart')
