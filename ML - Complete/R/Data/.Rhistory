rm(list=ls(all=TRUE))
state.x77
head(state.x77)
str(state.x77)
st = as.data.frame(state.x77)
data = as.data.frame(state.x77)
summary(data)
str(data)
head(state.x77)
colnames(st)[4] = "LifeExp"                   # no spaces in variable names, please
> colnames(st)[6] = "HSGrad"
colnames(st)[6] = "HSGrad"
cor(data)                              # correlation matrix (not shown, yet)
round(cor(data), 3)
colnames(data)[4] = "LifeExp"                   # no spaces in variable names, please
colnames(data)[6] = "HSGrad"
rm(list=ls(all=TRUE))
# we will use a builtin dataset
str(state.x77) # this is not a dataframe
data = as.data.frame(state.x77)
summary(data)
str(data)
head(state.x77)
# Data cleaning
colnames(data)[4] = "LifeExp"                   # no spaces in variable names, please
colnames(data)[6] = "HSGrad"
sapply(data, )
colnames(data)
str(state.x77) # this is not a dataframe
data = as.data.frame(state.x77)
summary(data)
str(data)
colnames(data)
colnames(data)[4] = "LifeExp"                   # no spaces in variable names, please
colnames(data)[6] = "HSGrad"
head(data)
sapply(data, min(),2)
sapply(data, min())
sapply(data,2, min())
sapply(data, min())
apply(data,2,min)
apply(data,2,max)
apply(data,2,mean)
pairs(st)
pairs(data)
model1 = lm(Life.Exp ~ ., data=st)
model1 = lm(Life.Exp ~ ., data=data)
model1 = lm(LifeExp ~ ., data=data)
summary(model1)
model2 = update(model1, .~. -Area)
summary(model2)
anova(model2, model1)
model3 = update(model2, .~. -Illiteracy)
summary(model3)
model4 = update(model3, .~. -Income)
summary(model4)
model5 = update(model4, .~. -Density)
summary(model5)
anova(model5, model4)
anova(model5, model1)
anova(model5, model4)
model.int = update(model5, .~.^3)
summary(model.int)
model.int = update(model5, .~.^3) # interaction effect
summary(model.int)
step(model1, direction="backward")
predict(model5, list(Population=2000, Murder=10.5, HS.Grad=48, Frost=100))
predict(model5, list(Population=2000, Murder=10.5, HSGrad=48, Frost=100))
par(mfrow=c(2,2))                    # visualize all four graphs at once
plot(model5)
par(mfrow=c(1,1))
par(mfrow=c(2,2))                    # visualize all four graphs at once
plot(model5)
par(mfrow=c(1,1))
names(model5)
coef(model5)
model5$coefficients
model5$resid
confint(model5)
rm(list=ls(all=TRUE))
str(state.x77) # this is not a dataframe
data = as.data.frame(state.x77)
View(data)
summary(data)
str(data)
colnames(data)[4] = "LifeExp"                   # no spaces in variable names, please
colnames(data)[6] = "HSGrad"
head(data)
apply(data,2,min)
apply(data,2,max)
apply(data,2,mean)
View(data)
View(data)
cor(data)                              # correlation matrix (not shown, yet)
round(cor(data), 3)
pairs(data) # Plot correlation matrix.
View(data)
View(data)
model1 = lm(LifeExp ~ ., data=data)
colnames(data)
View(data)
View(data)
summary(model1)
model2 = update(model1, .~. -Area)
summary(model2)
anova(model2, model1)
model3 = update(model2, .~. -Illiteracy)
summary(model3)
model4 = update(model3, .~. -Income)
summary(model4)
model5 = update(model4, .~. -Density)
summary(model5)
anova(model5, model4)
anova(model5, model1)
model.int = update(model5, .~.^3) # interaction effect
summary(model.int)
predict(model5, list(Population=2000, Murder=10.5, HSGrad=48, Frost=100))
par(mfrow=c(2,2))                    # visualize all four graphs at once
plot(model5)
par(mfrow=c(1,1))
plot(model5)
par(mfrow=c(2,2))                    # visualize all four graphs at once
plot(model5)
par(mfrow=c(1,1))
summary(model5)
names(model5)
model5$coefficients
model5$coefficients
model5$resid
confint(model5)
step(model1, direction="backward")
predict(model1, list(Population=2000, Murder=10.5, HSGrad=48, Frost=100))
model1 = lm(LifeExp ~ ., data=data)
summary(model1)
predict(model1, list(Population=2000, Murder=10.5, HSGrad=48, Frost=100))
rm(list=ls(all=TRUE))
# we will use a builtin dataset
str(state.x77) # this is not a dataframe
data = as.data.frame(state.x77)
summary(data)
str(data)
colnames(data)
# Data cleaning
colnames(data)[4] = "LifeExp"                   # no spaces in variable names, please
colnames(data)[6] = "HSGrad"
head(data)
apply(data,2,min)
apply(data,2,max)
apply(data,2,mean)
#
cor(data)                              # correlation matrix (not shown, yet)
round(cor(data), 3)
model1 = lm(LifeExp ~ ., data=data)
summary(model)
summary(model1)
rm(list=ls(all=TRUE))
data = as.data.frame(state.x77)
summary(data)
str(data)
colnames(data)
# Data cleaning
colnames(data)[4] = "LifeExp"                   # no spaces in variable names, please
colnames(data)[6] = "HSGrad"
head(data)
apply(data,2,min)
apply(data,2,max)
apply(data,2,mean)
#
cor(data)                              # correlation matrix (not shown, yet)
round(cor(data), 3)
pairs(data) # Plot correlation matrix.
model1 = lm(LifeExp ~ ., data=data)
summary(model1)
model_nnet<-train(trainSet[,predictors],trainSet[,predictVar],method='knn')
setwd("C:/Users/kulka/Downloads/Machine-Learning/ML - Complete/R/")
library(caret)
data <- read.csv("flags.csv")
data <- data[,-1]
index <- createDataPartition(data$landmass,p = 0.9,list = F)
trainSet <- data[index,]
testSet <- data[-index,]
predictVar <- "religion"
predictors<-names(trainSet)[!names(trainSet) %in% predictVar]
set.seed(22)
model_nnet<-train(trainSet[,predictors],trainSet[,predictVar],method='knn')
model_nnet<-train(trainSet[,predictors],trainSet[,predictVar],method='knn')
model_decision_trees<-train(trainSet[,predictors],trainSet[,predictVar],method='rpart')
setwd("C:/Users/kulka/Downloads/Machine-Learning/ML - Complete/R/Data")
data <- read.csv("germancredit.csv")
summary(data)
library(rpart)
index <- createDataPartition(data$GoodCredit,p = 0.8,list = F)
trainSet <- data[index,]
testSet <- data[-index,]
dmodel <- rpart(GoodCredit ~ .,data = trainSet)
dmodel
dmodel <- rpart(GoodCredit ~ .,data = trainSet, method = class)
dmodel <- rpart(GoodCredit ~ .,data = trainSet, method = "class")
plot(dmodel)
fit(text)
text(dmodel)
library(rattle)
library(rpart.plot)
library(RColorBrewer)
install.packages("rattle")
install.packages("rattle",dependencies = T)
library(rattle)
library(rattle)
library(rpart.plot)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
library(rpart.plot)
library(RColorBrewer)
fancyRpartPlot(dmodel)
test$predicted <- predict(fit, test, type = "class")
test$predicted <- predict(dmodel, test, type = "class")
testSet$predicted <- predict(dmodel, testSet, type = "class")
dmodel <- rpart(GoodCredit ~ .,
cp = 0.001,   # Set complexity parameter
maxdepth = 5, # Set maximum tree depth
minbucket = 5,
method = "class",
data = trainSet)
dmodel
plot(dmodel2)
dmodel1 <- rpart(GoodCredit ~ .,data = trainSet, method = "class")
dmodel2 <- rpart(GoodCredit ~ .,
fancyRpartPlot(dmodel2)
)
dmodel2 <- rpart(GoodCredit ~ .,
cp = 0.001,   # Set complexity parameter
maxdepth = 5, # Set maximum tree depth
minbucket = 5,
method = "class",
data = trainSet)
fancyRpartPlot(dmodel2)
confusionMatrix(testSet$GoodCredit,testSet$predicted)
dmodel2$variable.importance
library(C50)
install.packages(C50)
install.packages(c50)
install.packages("C50")
library(C50)
dmodel2 <- C50(GoodCredit ~ .,
cp = 0.001,   # Set complexity parameter
maxdepth = 5, # Set maximum tree depth
minbucket = 5,
method = "class",
data = trainSet)
dmodel3 <- C5.0(GoodCredit ~ .,
cp = 0.001,   # Set complexity parameter
maxdepth = 5, # Set maximum tree depth
minbucket = 5,
method = "class",
data = trainSet)
dmodel3 <- C5.0(GoodCredit ~ .,
trials = 10,
data = trainSet)
trainSet$GoodCredit <- as.factor(trainSet$GoodCredit)
dmodel3 <- C5.0(GoodCredit ~ .,
trials = 10,
data = trainSet)
library(randomForest)
library(randomForest)
rfmodel <- randomForest(GoodCredit ~.,
data = trainSet,
ntree=1000,            # Number of trees to grow
mtry=2)                # Number of branch variables
summary(rfmodel)
rfmodel$classes
rfmodel$type
rfmodel$forest
rfmodel$importanceSD
rfmodel$importance
rfmodel
testSet$predicted <- predict(rfmodel, testSet, type = "class")
confusionMatrix(testSet$GoodCredit,testSet$predicted)
testSet$predicted <- predict(dmodel, testSet, type = "class")
confusionMatrix(testSet$GoodCredit,testSet$predicted)
testSet$predicted <- predict(rfmodel, testSet, type = "class")
confusionMatrix(testSet$GoodCredit,testSet$predicted)
gbmModel <- train(GoodCredit ~ ., data = trainSet,
method = "gbm",
trControl = fitControl,
verbose = FALSE,
tuneGrid = gbmGrid)
gbmModel <- train(GoodCredit ~ ., data = trainSet,
method = "gbm",
trControl = fitControl,
verbose = FALSE,
tuneGrid = gbmGrid)
library("e1071")
svmmodel <- svm(GoodCredit ~.,data = trainSet)
testSet$predicted <- predict(rfmodel, testSet, type = "class")
confusionMatrix(testSet$GoodCredit,testSet$predicted)
svmmodel2 <- svm(GoodCredit ~.,
kernel = "radial",
gamma = if (is.vector(x)) 1 else 1 / ncol(x),
data = trainSet)
svmmodel2 <- svm(GoodCredit ~.,
kernel = "radial",
gamma = if (is.vector(GoodCredit)) 1 else 1 / ncol(x),
data = trainSet)
svmmodel2 <- svm(GoodCredit ~.,
kernel = "radial",
gamma = if (is.vector(trainSet$GoodCredit)) 1 else 1 / ncol(x),
data = trainSet)
1/6
svmmodel2 <- svm(GoodCredit ~.,
kernel = "radial",
gamma = 1,
data = trainSet)
library(class)
prc_train_labels <- trainSet$GoodCredit
prc_test_labels <- testSet$GoodCredit
knnmodel <- knn(train = trainSet, test = testSet,cl = prc_train_labels, k=10)
data <- read.csv("germancredit.csv")
summary(data)
index <- createDataPartition(data$GoodCredit,p = 0.8,list = F)
trainSet <- data[index,]
testSet <- data[-index,]
prc_train_labels <- trainSet$GoodCredit
prc_test_labels <- testSet$GoodCredit
knnmodel <- knn(train = trainSet, test = testSet,cl = prc_train_labels, k=10)
str(data)
setwd("C:/Users/kulka/Downloads/Machine-Learning/ML - Complete/R/Data")
data <- read.csv("flags.csv")
View(data)
index <- createDataPartition(data$landmass,p = 0.9,list = F)
data <- read.csv("flags.csv")
data <- data[,-1]
index <- createDataPartition(data$landmass,p = 0.9,list = F)
trainSet <- data[index,]
testSet <- data[-index,]
predictVar <- "religion"
predictors<-names(trainSet)[!names(trainSet) %in% predictVar]
set.seed(22)
model_decision_trees<-train(trainSet[,predictors],trainSet[,predictVar],method='rpart')
model_decision_trees<-train(trainSet[,predictors],trainSet[,predictVar],method='rf')
data <- read.csv("germancredit.csv")
summary(data)
trainSet <- data[index,]
testSet <- data[-index,]
summary(data)
index <- createDataPartition(data$GoodCredit,p = 0.8,list = F)
trainSet <- data[index,]
testSet <- data[-index,]
library(rpart)
dmodel1 <- rpart(GoodCredit ~ .,data = trainSet, method = "class")
dmodel1 <- rpart(GoodCredit ~ .,data = trainSet, method = "class")
plot(dmodel1)
text(dmodel1)
dmodel2$variable.importance
dmodel1$variable.importance
library(rattle)
library(rpart.plot)
library(RColorBrewer)
fancyRpartPlot(dmodel2)
fancyRpartPlot(dmodel1)
testSet$predicted <- predict(dmodel1, testSet, type = "class")
View(testSet)
View(index)
confusionMatrix(testSet$GoodCredit,testSet$predicted)
dmodel2 <- rpart(GoodCredit ~ .,
cp = 0.001,   # Set complexity parameter
maxdepth = 5, # Set maximum tree depth
minbucket = 5,
method = "class",
data = trainSet)
testSet$predicted <- predict(dmodel1, testSet, type = "class")
confusionMatrix(testSet$GoodCredit,testSet$predicted)
dmodel2 <- rpart(GoodCredit ~ .,
cp = 0.001,   # Set complexity parameter
maxdepth = 9, # Set maximum tree depth
minbucket = 5,
method = "class",
data = trainSet)
testSet$predicted <- predict(dmodel2, testSet, type = "class")
confusionMatrix(testSet$GoodCredit,testSet$predicted)
dmodel2 <- rpart(GoodCredit ~ .,
cp = 0.001,   # Set complexity parameter
maxdepth = 5, # Set maximum tree depth
minbucket = 5,
method = "class",
data = trainSet)
testSet$predicted <- predict(dmodel2, testSet, type = "class")
confusionMatrix(testSet$GoodCredit,testSet$predicted)
dmodel2 <- rpart(GoodCredit ~ .,
cp = 0.001,   # Set complexity parameter
maxdepth = 6, # Set maximum tree depth
minbucket = 5,
method = "class",
data = trainSet)
testSet$predicted <- predict(dmodel2, testSet, type = "class")
confusionMatrix(testSet$GoodCredit,testSet$predicted)
library(C50)
trainSet$GoodCredit <- as.factor(trainSet$GoodCredit)
dmodel3 <- C5.0(GoodCredit ~ .,
trials = 10,
data = trainSet)
dmodel1$variable.importance
dmodel3 <- C5.0(GoodCredit ~ .,
trials = 10,
data = trainSet)
testSet$predicted <- predict(dmodel3, testSet, type = "class")
confusionMatrix(testSet$GoodCredit,testSet$predicted)
library(randomForest)
rfmodel <- randomForest(GoodCredit ~.,
data = trainSet,
ntree=100,            # Number of trees to grow
mtry=2)                # Number of branch variables
testSet$predicted <- predict(rfmodel, testSet, type = "class")
confusionMatrix(testSet$GoodCredit,testSet$predicted)
rfmodel <- randomForest(GoodCredit ~.,
data = trainSet,
ntree=1000,            # Number of trees to grow
mtry=2)                # Number of branch variables
testSet$predicted <- predict(rfmodel, testSet, type = "class")
confusionMatrix(testSet$GoodCredit,testSet$predicted)
rfmodel <- randomForest(GoodCredit ~.,
data = trainSet,
ntree=1000,            # Number of trees to grow
mtry=3)                # Number of branch variables
testSet$predicted <- predict(rfmodel, testSet, type = "class")
confusionMatrix(testSet$GoodCredit,testSet$predicted)
summary(rfmodel)
rfmodel
rfmodel$classes
rfmodel$type
rfmodel$forest
rfmodel
dmodel2
summary(dmodel2)
model_decision_trees<-train(trainSet[,predictors],trainSet[,predictVar],method='glm')
data <- read.csv("flags.csv")
data <- data[,-1]
trainSet <- data[index,]
index <- createDataPartition(data$landmass,p = 0.9,list = F)
testSet <- data[-index,]
predictVar <- "religion"
predictors<-names(trainSet)[!names(trainSet) %in% predictVar]
set.seed(22)
library(caret)
model_decision_trees<-train(trainSet[,predictors],trainSet[,predictVar],method='glm')
model_decision_trees<-train(trainSet[,predictors],trainSet[,predictVar],method='lm')
library("e1071")
svmmodel1 <- svm(GoodCredit ~.,data = trainSet)
library(class)
data <- read.csv("germancredit.csv")
summary(data)
index <- createDataPartition(data$GoodCredit,p = 0.8,list = F)
testSet <- data[-index,]
trainSet <- data[index,]
svmmodel1 <- svm(GoodCredit ~.,data = trainSet)
svmmodel2 <- svm(GoodCredit ~.,
kernel = "radial",
gamma = 1,
data = trainSet)
svmmodel1 <- svm(GoodCredit ~.,data = trainSet)
svmmodel2 <- svm(GoodCredit ~.,
kernel = "radial",
gamma = 1,
data = trainSet)
testSet$predicted <- predict(rfmodel, testSet, type = "class")
confusionMatrix(testSet$GoodCredit,testSet$predicted)
knnmodel <- knn(train = trainSet, test = testSet,cl = prc_train_labels, k=10)
str(data)
knnmodel <- knn(train = trainSet, test = testSet,cl = prc_train_labels, k=10)
