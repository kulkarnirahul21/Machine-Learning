install.packages("caret")
install.packages("dplyr")
install.packages("ggplot2",dependencies = T)
install.packages("randomForest")
install.packages("C50")
install.packages("MASS")
install.packages("rJava")
install.packages("xgboost")
install.packages("h2o")
getwd()
setwd()
pwd()
install.packages("tm")
library(dplyr)
library(hflights)
data("hflights")
data(hflights)
head(hflights)
flights <- as.data.frame("hflights")
flights
View(flights)
flights <- as.data.frame(hflights)
View(flights)
flights <- tbl_df(hflights)
View(flights)
dim(flights)
print(flights,n=20)
head(flights)
print(flights,n=20)
flights[flights$Month == 1 & flights$DayofMonth =1,]
flights[flights$Month == 1 & flights$DayofMonth ==1,]
filter(flights,months ==1,DayofMonth ==1)
filter(flights, Month ==1,DayofMonth ==1)
a <- filter(flights, Month ==1,DayofMonth ==1)
b <- filter(TailNum = 'N576AA')
b <- filter(flights,TailNum = 'N576AA')
b <- filter(flights,TailNum == 'N576AA')
c <- filter(flights, Year == 2011)
rm(a,b,c)
a <- filter(flights, ArrDelay <= 0)
a <- filter(flights, ArrDelay > 0)
b <- filter(flights, ArrDelay < 0)
sum(106920, 109991)
c <- filter(flights, ArrDelay == 0)
sum(106920, 109991,6963)
d <- filter(flights, ArrDelay == 'NA')
is.na(flights$ArrDelay)
which(is.na(flights$ArrDelay))
flights[which(is.na(flights$ArrDelay)),]
a <- flights[which(is.na(flights$ArrDelay)),]
b <- filter(flights, TaxiIn == 'NA', TaxiOut == 'NA', ArrTime == 'NA')
b <- filter(flights, TaxiIn == 'NA', TaxiOut == 'NA')
b <- filter(flights, TaxiIn ='NA', TaxiOut ='NA')
b <- filter(flights, TaxiIn == 'NA', TaxiOut == 'NA')
b <- filter(flights, TaxiIn == 'NA', TaxiOut == 'NA')
a <- flights[which(is.na(flights$ArrDelay)),]
b <- filter(flights, TaxiIn == 'NA', TaxiOut == 'NA')
b <- filter(flights, TaxiIn == 'NA', TaxiOut == 'NA')
d <- filter(flights, ArrDelay == 'NA')
d <- filter(flights, ArrDelay = 'NA')
d <- filter(flights, ArrDelay = NA)
d <- filter(flights, ArrDelay == NA)
names(flights)
d <- flights[,"Month":"Origin"]
d <- flights[,c("Month":"Origin")]
d <- selct(flights, "Month":"Origin")
d <- select(flights, "Month":"Origin")
c <- flights[,Month:Origin]
c <- flights[,flights$Month:flights$Origin]
c <- flights[,c(flights$Month:flights$Origin)]
c <- flights[,2:9]
d <- select(flights,Month:Origin,contains(Taxi), contains(delay))
d <- select(flights,Month:Origin,contains("Taxi"), contains("delay"))
names(flights)
a <- names(flights)
View(a)
names(a) <- "Col.names"
View(a)
names(a)
a <- names(flights)
names(a)
names(a) <- "Col.names"
names(a)
View(a)
library(car)
summary(Prestige)
testidx <- which(1:nrow(Prestige)%%4==0)
testidx
prestige_train <- Prestige[-testidx,]
prestige_test <- Prestige[testidx,]
model <- lm(prestige~., data=prestige_train)
prediction <- predict(model, newdata=prestige_test)
rs <- residuals(model)
plot(model)
qqnorm(rs)
par(mfrow=c(1,1))
setwd("F:/INSOFE/Day-24/Decision_trees/resources/Rcode")
univ=read.table('univComp.csv',
header=T,sep=',')
# removing the id, Zip and experience as experience
#is correlated to age
univ=univ[,-c(1,3)]
class <- function(x){
x <- as.factor(x)
return(x)
}
univTemp <- data.frame(apply(univ[,9:17],2,class))
univ <- cbind(univ[,1:8], univTemp)
str(univ)
summary(univ)
#Splitting
rows=seq(1,4986,1)
set.seed(123)
trainRows=sample(rows,2986)
set.seed(123)
remainingRows=rows[-(trainRows)]
testRows=sample(remainingRows, 1000)
evalRows=rows[-c(trainRows,testRows)]
train = univ[trainRows,]
test=univ[testRows,]
eval=univ[evalRows,]
rm(univ,univTemp, evalRows,remainingRows,rows,testRows,trainRows, class)
summary(train)
library(rpart)
dtCart=rpart(inc ~.,data=train,
method="anova")
plot(dtCart,main="Classification Tree for Income",margin=0.15,uniform=TRUE)
text(dtCart,use.n=T)
predCartTrain=predict(dtCart,
newdata=train,
type="vector")
predCartTest=predict(dtCart,
newdata=test,
type="vector")
predCartEval=predict(dtCart,
newdata=eval,
type="vector")
library(DMwR)
setwd("C:/Users/kulka/Downloads/Machine-Learning/ML - Complete/Python/2 - Logistic Regression")
data <- read.csv("Affairs.csv")
data$affairs <- NULL
set.seed(22)
# To generate integers WITHOUT replacement:
trainIndex<-sample(1:6366,5000,replace = F)
train <- data[trainIndex,]
test <- data[-trainIndex,]
frmla <- "affair ~ rate_marriage + age + yrs_married + children + religious + educ + occupation + occupation_husb"
model1 <- glm(formula = frmla,data = train,family = "binomial") # Gauusian
#model1 <- glm(formula = frmla,data = train,family = binomial(link='logit'))
summary(model1)
# Residual deviance is the measure of lack of it
# Null deviance: some times model ignores some observation...so the measure of deviance on that reduced set.
frmla <- "affair ~ rate_marriage + age + yrs_married + religious + educ + occupation + occupation_husb"
model2 <- glm(formula = frmla,data = train,family = "binomial") # Gauusian
summary(model2)
frmla <- "affair ~ rate_marriage + age + yrs_married + religious + educ + occupation "
model3 <- glm(formula = frmla,data = train,family = "binomial") # Gauusian
summary(model3)
# anova(model1, test="Chisq")
test$pred <- predict(model1,newdata = test,type = 'response')
test$predicted <- ifelse(test$pred >= 0.5,1,0)
ConfMatrix <- as.data.frame(table(test$affair,test$predicted))
misClasificError <- mean(test$affair != test$predicted)
#true positives (TP): These are cases in which we predicted yes (they have the disease), and they do have the disease.
library(caret)
confusiMat <- confusionMatrix(test$affair,test$predicted)
confusiMat
ConfMatrix <- as.data.frame(table(test$affair,test$predicted))
misClasificError <- mean(test$affair != test$predicted)
#true positives (TP): These are cases in which we predicted yes (they have the disease), and they do have the disease.
#true negatives (TN): We predicted no, and they don't have the disease.
#false positives (FP): We predicted yes, but they don't actually have the disease. (Also known as a "Type I error.")
#false negatives (FN): He does have a disease, model predicted No (Also known as a "Type II error.")
ConfMatrix$names <- c("TN","FN","FP","TP")
# accuracy = (TN+TP)/Total
Accuracy <- (ConfMatrix$Freq[1] + ConfMatrix$Freq[4])/1366
# "Sensitivity" or "Recall" = (TP/FN+TP)
#When it's actually yes, how often does it predict yes?
recall <- ConfMatrix$Freq[4]/(ConfMatrix$Freq[2]+ConfMatrix$Freq[4])
recall
confusiMat
Accuracy
specifi <-  ConfMatrix$Freq[1]/(ConfMatrix$Freq[1] + ConfMatrix$Freq[3])
specifi
recall
precisi <- ConfMatrix$Freq[4]/(ConfMatrix$Freq[4] + ConfMatrix$Freq[3])
precisi
